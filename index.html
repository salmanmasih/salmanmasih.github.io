<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Salman Masih - Large Language Model</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    body {
      transition: background-color 0.3s, color 0.3s;
    }
    /* Justify content for the main text */
    .justified-text {
      text-align: justify;
      line-height: 1.8;
    }
    .highlight-orange {
      color: #f4a300; /* Orange */
      font-weight: bold;
    }
    .highlight-blue {
      color: #1e90ff; /* Dodger Blue */
      font-weight: bold;
    }
    .highlight-green {
      color: #32cd32; /* Lime Green */
      font-weight: bold;
    }
    .highlight-red {
      color: #ff6347; /* Tomato Red */
      font-weight: bold;
    }
    .highlight-purple {
      color: #8a2be2; /* Blue Violet */
      font-weight: bold;
    }
  </style>
</head>

<body class="bg-white text-gray-900 font-sans">
<header class="bg-gray-100 p-4 shadow-md">
  <div class="max-w-7xl mx-auto flex justify-center items-center">
    <nav class="flex space-x-6 text-sm">
      <a href="index.html#about" class="hover:underline">Home</a>
      <a href="publications.html" class="hover:underline">Publications</a>
      <a href="courses.html" class="hover:underline">Courses & Specializations</a>
      <a href="reading.html" class="hover:underline">Reading</a>
      <a href="teaching.html" class="hover:underline">Teaching</a>
      <a href="workshops.html" class="hover:underline">Workshops & Tutorials</a>
    </nav>
  </div>
</header>

  <!-- Main layout with sidebar + content -->
  <main class="max-w-7xl mx-auto px-6 py-12 flex flex-col md:flex-row gap-12">
    
<!-- Sidebar (left) -->
<aside class="md:w-1/4 flex flex-col items-center space-y-4 mb-8 md:mb-0">
  <img src="assets/images/IMG-20211228-WA0002.jpg" alt="Salman Masih" class="rounded-full w-40 h-40 object-cover shadow-md">
  <h2 class="text-xl font-semibold">Salman Masih</h2>
  
  <div class="flex flex-col space-y-2 w-full text-center text-sm">
    <a href="https://scholar.google.com/citations?user=your_id" target="_blank" class="text-blue-600 hover:underline">Google Scholar</a>
    <a href="https://twitter.com/your_username" target="_blank" class="text-blue-400 hover:underline">Twitter</a>
    <a href="https://linkedin.com/in/your_username" target="_blank" class="text-blue-700 hover:underline">LinkedIn</a>
    <a href="https://www.researchgate.net/profile/your_name" target="_blank" class="text-green-600 hover:underline">ResearchGate</a>
    <a href="https://medium.com/@your_username" target="_blank" class="text-gray-800 hover:underline">Medium</a>
    <a href="https://github.com/salmanmasih" target="_blank" class="text-black hover:underline">GitHub</a>
    <a href="https://huggingface.co/your_username" target="_blank" class="text-pink-600 hover:underline">Hugging Face</a>
  </div>
</aside>

    <!-- Content (right) -->
    <section class="md:w-3/4 space-y-12">
      
      <!-- News Banner Section -->
      <section id="news" class="bg-blue-500 text-white py-8 mt-12 rounded-lg">
        <h3 class="text-2xl font-bold text-center">Latest News</h3>
        <div class="mt-4">
          <p class="bg-yellow-300 p-2 rounded-md font-bold text-black animate-pulse">
            Published Alert!
            <a href="https://www.mdpi.com/2079-9292/14/12/2320" target="_blank" class="text-blue-800 underline">
              Transformer-Based Abstractive Summarization of Legal Texts in Low-Resource Languages
            </a>
          </p>
        </div>
      </section>

      <!-- About Me Section -->
      <section id="about">
        <h2 class="text-3xl font-bold">About Me</h2>
        <p class="justified-text">Iâ€™m Salman Masih, a Ph.D. researcher in Computer Science, specializing in <span class="highlight-blue">Natural Language Processing (NLP)</span>. My work focuses on <span class="highlight-green">multilingual models</span>, <span class="highlight-orange">legal text summarization</span>, and <span class="highlight-purple">fairness in large language models (LLMs)</span> for <span class="highlight-red">low-resource languages</span> like <span class="highlight-blue">Urdu</span>. I aim to tackle challenges in applying advanced NLP techniques to legal documents in languages with limited annotated resources, developing efficient, accurate, and fair models.</p>
        <p class="justified-text">My thesis centers on <span class="highlight-orange">abstractive text summarization</span> for <span class="highlight-red">low-resource languages</span>, particularly <span class="highlight-blue">Urdu</span>, and includes four key papers on <span class="highlight-blue">transformer-based summarization</span>, <span class="highlight-green">few-shot</span> and <span class="highlight-green">zero-shot learning</span>, <span class="highlight-orange">architectural comparisons</span>, and <span class="highlight-purple">parameter-efficient fine-tuning</span>.</p>

        <h3 class="text-xl font-semibold mt-8">Research Interests</h3>
        <p class="justified-text">My research interests span multiple areas of <span class="highlight-blue">Natural Language Processing (NLP)</span>. I focus on developing techniques for <span class="highlight-green">multilingual NLP</span>, particularly for <span class="highlight-red">low-resource languages</span> such as <span class="highlight-blue">Urdu</span>, intending to improve model performance in multilingual settings. A core area of my work is <span class="highlight-orange">Natural Language Understanding (NLU)</span> and <span class="highlight-orange">Natural Language Generation (NLG)</span>, where I enhance models' ability to comprehend <span class="highlight-orange">legal text</span> and generate high-quality, accurate summaries while preserving <span class="highlight-green">factual</span> and <span class="highlight-green">semantic integrity</span>.</p>
        <p class="justified-text">Additionally, I work on <span class="highlight-blue">language modeling</span>, fine-tuning <span class="highlight-purple">large language models (LLMs)</span> to perform tasks like <span class="highlight-orange">summarization</span>, <span class="highlight-orange">translation</span>, and <span class="highlight-orange">classification</span> in low-resource settings. I specialize in <span class="highlight-orange">legal text summarization</span>, particularly <span class="highlight-orange">abstractive summarization</span> of <span class="highlight-orange">legal documents</span> in <span class="highlight-red">low-resource languages</span>, ensuring the generated summaries are <span class="highlight-green">concise</span>, <span class="highlight-green">accurate</span>, and <span class="highlight-green">legally sound</span>. My research also addresses <span class="highlight-green">hallucination mitigation</span>, aiming to reduce instances of fabricated or inaccurate content in generated text.</p>
        <p class="justified-text">I investigate <span class="highlight-orange">cross-lingual fairness</span> to ensure NLP models perform equitably across <span class="highlight-green">high-resource</span> and <span class="highlight-red">low-resource languages</span>, preventing <span class="highlight-green">biases</span> and <span class="highlight-green">performance disparities</span>. In the realm of <span class="highlight-purple">LLMs in multilingual settings</span>, I focus on enhancing model performance for <span class="highlight-red">low-resource languages</span> through techniques like <span class="highlight-green">transfer learning</span>, <span class="highlight-green">fine-tuning</span>, and <span class="highlight-green">domain adaptation</span>. I am particularly interested in <span class="highlight-purple">Parameter-Efficient Fine-Tuning (PEFT)</span> and techniques like <span class="highlight-purple">LoRA (Low-Rank Adaptation)</span>, which provide efficient ways to adapt large models to specific tasks while minimizing computational resources.</p>
        <p class="justified-text">Additionally, I explore <span class="highlight-blue">tokenless NLP</span>, an emerging approach in multilingual modeling that bypasses traditional <span class="highlight-orange">tokenization</span> to process raw text directly, offering potential improvements in <span class="highlight-green">efficiency</span> and <span class="highlight-green">robustness</span>, particularly for <span class="highlight-red">low-resource languages</span>. Lastly, I am interested in <span class="highlight-purple">interpretable NLP</span>, specifically developing transparent models that provide <span class="highlight-green">explainable outputs</span>, particularly in sensitive applications such as <span class="highlight-orange">legal domains</span>, where <span class="highlight-green">model decisions</span> need to be understood and justified.</p>

        <h3 class="text-xl font-semibold mt-8">Further Details, Here is Complete CV Last Updated: 7th June 2025</h3>
        <p class="justified-text">For more details on my academic background, experience, and skills, please refer to my <a href="assets/pdf/Salman_Masih_CV.pdf" class="text-blue-500 underline" target="_blank">CV (PDF)</a>.</p>
      </section>

    </section>
  </main>

  <footer class="bg-gray-100 dark:bg-gray-800 text-center p-4 mt-12">
    <p>&copy; 2025 Salman Masih. Built with Tailwind CSS. Hosted on GitHub Pages.</p>
  </footer>
</body>
</html>
